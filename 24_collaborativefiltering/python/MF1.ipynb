{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "class MF(object):\n",
    "    def __init__(self, Y, k, X = None, W = None, lamda = 0.1,\n",
    "                dist_func = cosine_similarity, learning_rate = 0.5, max_iter = 1000, user_based = 1, limit = 10):\n",
    "#         self.f = open('danhgiaMF.dat', 'a+')\n",
    "        self.Y = Y\n",
    "        self.lamda = lamda\n",
    "        self.k = k\n",
    "        self.dist_func = dist_func\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.user_based = user_based\n",
    "        self.limit = limit\n",
    "        self.users_count = int(np.max(self.Y[:, 0])) + 1\n",
    "        self.items_count = int(np.max(self.Y[:, 1])) + 1\n",
    "        self.ratings_count = Y.shape[0]\n",
    "        if X == None:\n",
    "            self.X = np.random.randn(self.items_count, k)\n",
    "        if W == None:\n",
    "            self.W = np.random.randn(k, self.users_count)\n",
    "        self.Ybar = self.Y.copy()\n",
    "        \n",
    "    def normalizeY(self):\n",
    "        if self.user_based:\n",
    "            user_col = 0\n",
    "            item_col = 1\n",
    "            n_objects = self.users_count\n",
    "        else:\n",
    "            user_col = 1\n",
    "            item_col = 0 \n",
    "            n_objects = self.items_count\n",
    "        users = self.Y[:, user_col]\n",
    "        self.mu = np.zeros((n_objects,))\n",
    "        for i in range(n_objects):\n",
    "            ids = np.where(users == i)[0].astype(int)\n",
    "            ratings = self.Y[ids, 2]\n",
    "            m = np.mean(ratings)\n",
    "            if np.isnan(m):\n",
    "                m = 0\n",
    "            self.mu[i] = m\n",
    "            self.Ybar[ids, 2] = ratings - self.mu[i]\n",
    "#         print(self.Ybar)\n",
    "    \n",
    "    def get_user_rated_item(self, i):\n",
    "        ids = np.where(i == self.Ybar[:, 1])[0].astype(int)\n",
    "        users = self.Ybar[ids, 0].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (users, ratings)\n",
    "        \n",
    "\n",
    "    def get_item_rated_by_user(self, u):\n",
    "        ids = np.where(u == self.Ybar[:, 0])[0].astype(int)\n",
    "        items = self.Ybar[ids, 1].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (items, ratings)\n",
    "    \n",
    "    def updateX(self):\n",
    "        for i in range(self.items_count):\n",
    "            users, ratings = self.get_user_rated_item(i)\n",
    "            Wi = self.W[:, users]\n",
    "            a = -(ratings - self.X[i, :].dot(Wi)).dot(Wi.T)/self.ratings_count + \\\n",
    "            self.lamda*self.X[i, :]\n",
    "            self.X[i, :] -= self.learning_rate*(a).reshape((self.k,))\n",
    "        \n",
    "    def updateW(self):\n",
    "        for u in range(self.users_count):\n",
    "            items, ratings = self.get_item_rated_by_user(u)\n",
    "            Xn = self.X[items, :]\n",
    "            a = -Xn.T.dot(ratings - Xn.dot(self.W[:, u]))/self.ratings_count + self.lamda*self.W[:, u]\n",
    "            self.W[:, u] -= self.learning_rate*(a).reshape((self.k,))\n",
    "        \n",
    "    def fit(self, x, data_size, Data_test, test_size = 0):\n",
    "        self.normalizeY()\n",
    "        for i in range(self.max_iter):\n",
    "            self.updateX()\n",
    "            self.updateW()\n",
    "            if (i + 1) % x == 0:\n",
    "                print(i + 1)\n",
    "                self.RMSE(data_size, Data_test, test_size = 0)\n",
    "                self.evaluate(data_size, Data_test, test_size = 0)\n",
    "            \n",
    "    def pred(self, u, i):\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        if self.user_based:\n",
    "            bias = self.mu[u]\n",
    "        else: \n",
    "            bias = self.mu[i]\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + bias\n",
    "        \n",
    "        if pred < 1:\n",
    "            return 1 \n",
    "        if pred > 5: \n",
    "            return 5 \n",
    "        return pred\n",
    "    \n",
    "    def recommend(self, u):\n",
    "        ids = np.where(self.Y[:, 0] == u)[0].astype(int)\n",
    "        items_rated_by_user = self.Y[ids, 1].tolist()\n",
    "        if self.user_based:\n",
    "            bias = self.mu[u]\n",
    "        else: \n",
    "            bias = self.mu[i]\n",
    "        pred = self.X.dot(self.W[:, u]) + bias\n",
    "        a = np.zeros((self.items_count,))\n",
    "        recommended_items = []\n",
    "        for i in range(self.items_count):\n",
    "            if i not in items_rated_by_user:\n",
    "                a[i] = pred[i]\n",
    "        if len(a) < self.limit:\n",
    "            recommended_items = np.argsort(a)[-self.items_count:]\n",
    "        else:\n",
    "            recommended_items = np.argsort(a)[-self.limit:]\n",
    "        recommended_items = np.where(a[:] > 0)[0].astype(int)\n",
    "\n",
    "#         return random.sample(list(recommended_items), self.limit)\n",
    "        return recommended_items[:self.limit]\n",
    "#         return recommended_items\n",
    "    \n",
    "    def RMSE(self, data_size, Data_test, test_size = 0):\n",
    "        n_tests = Data_test.shape[0]\n",
    "        SE = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(Data_test[n, 0], Data_test[n, 1])\n",
    "            SE += (pred - Data_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        print('RMSE =', RMSE)\n",
    "        if self.user_based:\n",
    "            print('%s::1::%d::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k, self.max_iter, test_size, RMSE))\n",
    "#             self.f.write('%s::1::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k,self.max_iter, test_size, RMSE))\n",
    "        else:\n",
    "            print('%s::0::%d::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k, self.max_iter, test_size, RMSE))\n",
    "#             self.f.write('%s::0::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k, test_size, RMSE))\n",
    "#         self.f.close()\n",
    "    \n",
    "    def evaluate(self, data_size, Data_test, test_size = 0):\n",
    "        sum_p = 0\n",
    "        sum_r = 0\n",
    "        self.Pu = np.zeros((self.users_count,))\n",
    "        for u in range(self.users_count):\n",
    "            recommended_items = self.recommend(u)\n",
    "            ids = np.where(Data_test[:, 0] == u)[0]\n",
    "            rated_items = Data_test[ids, 1]\n",
    "            for i in rated_items:\n",
    "                if i in recommended_items:\n",
    "                    self.Pu[u] += 1\n",
    "                if Data_test[i, 2] > 3:\n",
    "                    sum_r += 1\n",
    "            sum_p += self.Pu[u]\n",
    "        \n",
    "        p = sum_p/(self.users_count * self.limit)\n",
    "        r = sum_p/sum_r\n",
    "        print('%s::0::%d::%d::cosine_similarity::%r::%r::%r\\r\\n' % (str(data_size), self.k, self.max_iter, test_size, p, r))\n",
    "        return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "class MF2(object):\n",
    "    def __init__(self, Y, n_factors = 2, X = None, W = None, lamda = 0.1, lr = 2, n_epochs = 50, user_based = 1, \n",
    "                 limit = 10):\n",
    "#         self.f = open('danhgiaMF.dat', 'a+')\n",
    "        self.Y = Y\n",
    "        self.lamda = lamda\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.user_based = user_based\n",
    "        self.limit = limit\n",
    "        self.users_count = int(np.max(self.Y[:, 0])) + 1\n",
    "        self.items_count = int(np.max(self.Y[:, 1])) + 1\n",
    "        self.ratings_count = Y.shape[0]\n",
    "        if X == None:\n",
    "            self.X = np.random.randn(self.items_count, n_factors)\n",
    "        if W == None:\n",
    "            self.W = np.random.randn(n_factors, self.users_count)\n",
    "        self.Ybar = self.Y.copy()\n",
    "        \n",
    "        self.bi = np.random.randn(self.items_count)\n",
    "        self.bu = np.random.randn(self.users_count)\n",
    "        self.n_ratings = self.Y.shape[0]\n",
    "        \n",
    "    def normalizeY(self):\n",
    "        if self.user_based:\n",
    "            user_col = 0\n",
    "            item_col = 1\n",
    "            n_objects = self.users_count\n",
    "        else:\n",
    "            user_col = 1\n",
    "            item_col = 0 \n",
    "            n_objects = self.items_count\n",
    "        users = self.Y[:, user_col]\n",
    "        self.mu = np.zeros((n_objects,))\n",
    "        for i in range(n_objects):\n",
    "            ids = np.where(users == i)[0].astype(int)\n",
    "            ratings = self.Y[ids, 2]\n",
    "            m = np.mean(ratings)\n",
    "            if np.isnan(m):\n",
    "                m = 0\n",
    "            self.mu[i] = m\n",
    "            self.Ybar[ids, 2] = ratings - self.mu[i]\n",
    "#         print(self.Ybar)\n",
    "    \n",
    "    def get_user_rated_item(self, i):\n",
    "        ids = np.where(i == self.Ybar[:, 1])[0].astype(int)\n",
    "        users = self.Ybar[ids, 0].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (users, ratings)\n",
    "        \n",
    "\n",
    "    def get_item_rated_by_user(self, u):\n",
    "        ids = np.where(u == self.Ybar[:, 0])[0].astype(int)\n",
    "        items = self.Ybar[ids, 1].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (items, ratings)\n",
    "    \n",
    "    def updateX(self):\n",
    "        for m in range(self.items_count):\n",
    "            users, ratings = self.get_user_rated_item(m)\n",
    "            Wm = self.W[:, users]\n",
    "            b = self.bu[users]\n",
    "            sum_grad_xm = np.full(shape = (self.X[m].shape) , fill_value = 1e-8)\n",
    "            sum_grad_bm = 1e-8\n",
    "            for i in range(50):\n",
    "                xm = self.X[m]\n",
    "                error = xm.dot(Wm) + self.bi[m] + b - ratings\n",
    "                grad_xm = error.dot(Wm.T)/self.n_ratings + self.lamda*xm\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                sum_grad_xm += grad_xm**2\n",
    "                sum_grad_bm += grad_bm**2\n",
    "                # gradient descent\n",
    "                self.X[m] -= self.lr*grad_xm.reshape(-1)/np.sqrt(sum_grad_xm)\n",
    "                self.bi[m] -= self.lr*grad_bm/np.sqrt(sum_grad_bm)\n",
    "        \n",
    "    def updateW(self):\n",
    "        for n in range(self.users_count):\n",
    "            items, ratings = self.get_item_rated_by_user(n)\n",
    "            Xn = self.X[items, :]\n",
    "            b = self.bi[items]\n",
    "            sum_grad_wn = np.full(shape = (self.W[:, n].shape) , fill_value = 1e-8).T\n",
    "            sum_grad_bn = 1e-8\n",
    "            for i in range(50):\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + self.bu[n] + b - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lamda*wn\n",
    "                grad_bn = np.sum(error)/self.n_ratings\n",
    "                sum_grad_wn += grad_wn**2\n",
    "                sum_grad_bn += grad_bn**2\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= self.lr*grad_wn.reshape(-1)/np.sqrt(sum_grad_wn)\n",
    "                self.bu[n] -= self.lr*grad_bn/np.sqrt(sum_grad_bn)\n",
    "\n",
    "    def fit(self, x, data_size, Data_test, test_size = 0):\n",
    "        self.normalizeY()\n",
    "        for i in range(self.n_epochs):\n",
    "            self.updateW()\n",
    "            self.updateX()\n",
    "            if (i + 1) % x == 0:\n",
    "                print(i + 1)\n",
    "                self.RMSE(Data_test, test_size = 0)\n",
    "                self.evaluate(data_size, Data_test, test_size = 0)\n",
    "            \n",
    "    def pred(self, u, i):\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        if self.user_based:\n",
    "            bias = self.mu[u]\n",
    "        else: \n",
    "            bias = self.mu[i]\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.bi[i] + self.bu[u] + bias\n",
    "        \n",
    "        if pred < 1:\n",
    "            return 1 \n",
    "        if pred > 5: \n",
    "            return 5 \n",
    "        return max(0, min(5, pred))\n",
    "    \n",
    "    def recommend(self, u):\n",
    "        ids = np.where(self.Y[:, 0] == u)[0].astype(int)\n",
    "        items_rated_by_user = self.Y[ids, 1].tolist()\n",
    "        a = np.zeros((self.items_count,))\n",
    "        recommended_items = []\n",
    "        pred = self.X.dot(self.W[:, u])\n",
    "        for i in range(self.items_count):\n",
    "            if i not in items_rated_by_user:\n",
    "                if self.user_based:\n",
    "                    bias = self.mu[u]\n",
    "                else: \n",
    "                    bias = self.mu[i]\n",
    "                a[i] = pred[i] +self.bi[i] + self.bu[u] + bias\n",
    "        if len(a) < self.limit:\n",
    "            recommended_items = np.argsort(a)[-self.items_count:]\n",
    "        else:\n",
    "            recommended_items = np.argsort(a)[-self.limit:]\n",
    "        recommended_items = np.where(a[:] > 0)[0].astype(int)\n",
    "\n",
    "#         return random.sample(list(recommended_items), self.limit)\n",
    "        return recommended_items[:self.limit]\n",
    "#         return recommended_items\n",
    "    \n",
    "    def RMSE(self, Data_test, test_size = 0, data_size = '100K'):\n",
    "        n_tests = Data_test.shape[0]\n",
    "        SE = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(Data_test[n, 0], Data_test[n, 1])\n",
    "            SE += (pred - Data_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        print('RMSE =', RMSE)\n",
    "        if self.user_based:\n",
    "            print('%s::1::%d::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.n_factors, self.n_epochs, test_size, RMSE))\n",
    "#             self.f.write('%s::1::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.n_factors,self.n_epochs, test_size, RMSE))\n",
    "        else:\n",
    "            print('%s::0::%d::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.n_factors, self.n_epochs, test_size, RMSE))\n",
    "#             self.f.write('%s::0::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.n_factors, test_size, RMSE))\n",
    "#         self.f.close()\n",
    "        return RMSE\n",
    "    \n",
    "    def evaluate(self, data_size, Data_test, test_size = 0):\n",
    "        sum_p = 0\n",
    "        sum_r = 0\n",
    "        self.Pu = np.zeros((self.users_count,))\n",
    "        for u in range(self.users_count):\n",
    "            recommended_items = self.recommend(u)\n",
    "            ids = np.where(Data_test[:, 0] == u)[0]\n",
    "            rated_items = Data_test[ids, 1]\n",
    "            for i in recommended_items:\n",
    "                if i in rated_items:\n",
    "                    self.Pu[u] += 1\n",
    "                if Data_test[i, 2] >= 4.5:\n",
    "                    sum_r += 1\n",
    "            sum_p += self.Pu[u]\n",
    "        print('sump', sum_p, sum_r)\n",
    "        p = sum_p/(self.users_count * self.limit)\n",
    "        r = sum_p/sum_r\n",
    "        print('%s::0::%d::%d::cosine_similarity::%r::%r::%r\\r\\n' % (str(data_size), self.n_factors, self.n_epochs, test_size, p, r))\n",
    "        return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.981551914764402\n",
      "1M::0::2::cosine_similarity::0.2::0.981551914764402\n",
      "\n",
      "RMSE = 1.037606663188771\n",
      "1M::1::2::cosine_similarity::0.2::1.037606663188771\n",
      "\n",
      "RMSE = 0.9806335336422325\n",
      "1M::0::2::cosine_similarity::0.30000000000000004::0.9806335336422325\n",
      "\n",
      "RMSE = 1.0369936764645347\n",
      "1M::1::2::cosine_similarity::0.30000000000000004::1.0369936764645347\n",
      "\n",
      "RMSE = 0.980216476770738\n",
      "1M::0::2::cosine_similarity::0.4000000000000001::0.980216476770738\n",
      "\n",
      "RMSE = 1.0362479676878835\n",
      "1M::1::2::cosine_similarity::0.4000000000000001::1.0362479676878835\n",
      "\n",
      "RMSE = 0.9817307666356478\n",
      "1M::0::2::cosine_similarity::0.5000000000000001::0.9817307666356478\n",
      "\n",
      "RMSE = 1.0378532872672301\n",
      "1M::1::2::cosine_similarity::0.5000000000000001::1.0378532872672301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestemp']\n",
    "ratings = pd.read_csv('mvl/1M.dat', sep = '::', names = r_cols, encoding='latin-1')\n",
    "Y_data = ratings.as_matrix()\n",
    "for testSize in np.arange(0.2, 0.6, 0.1):\n",
    "    Data_train, Data_test= train_test_split(Y_data, test_size=testSize, random_state=20)\n",
    "    for j in [0, 1]:\n",
    "        rs = MF(Data_train, k = 2, lamda = 0.1, learning_rate = 2, max_iter = 10, user_based = j)\n",
    "        rs.fit()\n",
    "        rs.RMSE('1M', Data_test, test_size = testSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('mvl/10M.dat', sep = '::', names = r_cols, encoding='latin-1')\n",
    "Y_data = ratings.as_matrix()\n",
    "\n",
    "for testSize in np.arange(0.1, 0.5, 0.1):\n",
    "    Data_train, Data_test= train_test_split(Y_data, test_size=testSize, random_state=20)\n",
    "    for x in [2, 5, 10]:\n",
    "        rs = MF(Data_train, k = x, lamda = 0.1, learning_rate = 2, max_iter = 10, user_based = 0)\n",
    "        rs.fit()\n",
    "        rs.RMSE('10M', Data_test, test_size = testSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestemp']\n",
    "\n",
    "ratings_base_1 = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1', engine='python')\n",
    "ratings_test_1 = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1', engine='python')\n",
    "\n",
    "ratings_matrix_1 = ratings_base_1.as_matrix()\n",
    "ratings_matrix = ratings_test_1.as_matrix()\n",
    "\n",
    "ratings_matrix_1[:, :2] -= 1\n",
    "ratings_matrix[:, :2] -= 1\n",
    "\n",
    "rs_1 = MF(ratings_matrix_1, k = 100, lamda = 0.01, learning_rate = 2)\n",
    "rs.fit(100, \n",
    "\n",
    "rs_1.RMSE(\"100K\", ratings_matrix, test_size = testSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'item_id', 'rating']\n",
    "ratings = pd.read_csv('ex.dat', sep = ' ', names = r_cols, encoding='latin-1')\n",
    "Y_data = ratings.as_matrix()\n",
    "\n",
    "rs = MF(Y_data, k = 2)\n",
    "\n",
    "rs.fit()\n",
    "rs.pred(6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "r_cols = ['dataset', 'uMF', 'k','dist_func', 'test_size', 'RMSE']\n",
    "\n",
    "RMSEs = pd.read_csv('danhgiaMF.dat', sep='::', names=r_cols, encoding='latin-1', engine='python')\n",
    "\n",
    "rs = RMSEs.as_matrix()\n",
    "print(RMSEs)\n",
    "dataset = rs[:, 0]\n",
    "uMF = rs[:, 1]\n",
    "\n",
    "for n in ['100K', '1M']:\n",
    "    ids_ii = np.where((dataset == n) & (uMF == 0))[0].astype(np.int32)\n",
    "    ids_uu = np.where((dataset == n) & (uMF == 1))[0].astype(np.int32)\n",
    "    items_ii = rs[ids_ii, 5]\n",
    "    items_uu = rs[ids_uu, 5]\n",
    "    t_ii = range(1, ids_ii.shape[0] + 1, 1)\n",
    "    t_uu = range(1, ids_uu.shape[0] + 1, 1)\n",
    "    plt.plot(t_ii, items_ii, 'g^', t_uu, items_uu, 'bs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "RMSE = 2.08723384117777\n",
      "100K::1::10::1000::cosine_similarity::0::2.08723384117777\n",
      "\n",
      "100K::0::10::1000::cosine_similarity::0::0.011672185430463576::0.00236640708915145\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9f7222ac162b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# for i in np.arange(1, 11, 1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'100K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-27548efdb030>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, data_size, Data_test, test_size)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-27548efdb030>\u001b[0m in \u001b[0;36mupdateW\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdateW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_item_rated_by_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mXn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mXn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratings_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-27548efdb030>\u001b[0m in \u001b[0;36mget_item_rated_by_user\u001b[0;34m(self, u)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_item_rated_by_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYbar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYbar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYbar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('1M_train1.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('1M_test1.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "# # indices start from 0\n",
    "# rate_train[:, :2] -= 1\n",
    "# rate_test[:, :2] -= 1\n",
    "\n",
    "# for i in np.arange(1, 11, 1):\n",
    "rs = MF(rate_train, k = 10, lamda = 1, learning_rate = 2, max_iter = 1000)\n",
    "rs.fit(100, '100K', rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "100\n",
    "RMSE = 0.8913244821881572\n",
    "100K::1::10::1000::cosine_similarity::0::0.8913244821881572\n",
    "\n",
    "100K::0::10::1000::cosine_similarity::0::0.013509933774834438::0.0027389903329752955\n",
    "\n",
    "200\n",
    "RMSE = 0.8913244821881572\n",
    "100K::1::10::1000::cosine_similarity::0::0.8913244821881572\n",
    "\n",
    "100K::0::10::1000::cosine_similarity::0::0.013509933774834438::0.0027389903329752955\n",
    "\n",
    "300\n",
    "RMSE = 0.8913244821881572\n",
    "100K::1::10::1000::cosine_similarity::0::0.8913244821881572\n",
    "\n",
    "100K::0::10::1000::cosine_similarity::0::0.013509933774834438::0.0027389903329752955\n",
    "\n",
    "400\n",
    "RMSE = 0.8913244821881572\n",
    "100K::1::10::1000::cosine_similarity::0::0.8913244821881572\n",
    "\n",
    "100K::0::10::1000::cosine_similarity::0::0.013509933774834438::0.0027389903329752955\n",
    "\n",
    "500\n",
    "RMSE = 0.8913244821881572\n",
    "100K::1::10::1000::cosine_similarity::0::0.8913244821881572\n",
    "\n",
    "100K::0::10::1000::cosine_similarity::0::0.013509933774834438::0.0027389903329752955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1\n",
    "30\n",
    "RMSE = 1.061960663169275\n",
    "1.061960663169275\n",
    "2\n",
    "30\n",
    "RMSE = 1.062749446086973\n",
    "1.062749446086973\n",
    "3\n",
    "30\n",
    "RMSE = 1.0632309128657713\n",
    "1.0632309128657713\n",
    "4\n",
    "30\n",
    "RMSE = 1.065408051857591\n",
    "1.065408051857591\n",
    "5\n",
    "30\n",
    "RMSE = 1.0658117505594327\n",
    "1.0658117505594327\n",
    "6\n",
    "30\n",
    "RMSE = 1.0669805777207546\n",
    "1.0669805777207546\n",
    "7\n",
    "30\n",
    "RMSE = 1.0664761227724426\n",
    "1.0664761227724426\n",
    "8\n",
    "30\n",
    "RMSE = 1.069384631857391\n",
    "1.069384631857391\n",
    "9\n",
    "30\n",
    "RMSE = 1.0672201096462794\n",
    "1.0672201096462794\n",
    "10\n",
    "30\n",
    "RMSE = 1.0709619647969306\n",
    "1.0709619647969306"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
