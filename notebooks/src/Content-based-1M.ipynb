{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "u_cols =  ['user_id', 'sex', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', names=u_cols,\n",
    " encoding='latin-1')\n",
    "n_users = users.shape[0]\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('mvl_can/1M_train_03.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('mvl_can/1M_test_03.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "i_cols = ['movie id', 'title' ,'year', 'gen']\n",
    "n_items = 3951\n",
    "\n",
    "items = pd.read_csv('ml-1m/movies.dat', sep='::', names=i_cols, encoding='latin-1')\n",
    "X = items.as_matrix()\n",
    "X_train_count = np.full(shape = (n_items, 19), fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genresList = [\n",
    "  \"Action\",\n",
    "  \"Adventure\",\n",
    "  \"Animation\",\n",
    "  \"Children\",\n",
    "  \"Comedy\",\n",
    "  \"Crime\",\n",
    "  \"Documentary\",\n",
    "  \"Drama\",\n",
    "  \"Fantasy\",\n",
    "  \"Film-Noir\",\n",
    "  \"Horror\",\n",
    "  \"Musical\",\n",
    "  \"Mystery\",\n",
    "  \"Romance\",\n",
    "  \"Sci-Fi\",\n",
    "  \"Thriller\",\n",
    "  \"War\",\n",
    "  \"Western\",\n",
    "  \"(no genres listed)\"\n",
    "]\n",
    "\n",
    "def setGenresMatrix(genres):\n",
    "    movieGenresMatrix = []\n",
    "    movieGenresList = genres.split('|')\n",
    "    for x in genresList:\n",
    "        if (x in movieGenresList):\n",
    "            movieGenresMatrix.append(1)\n",
    "        else:\n",
    "            movieGenresMatrix.append(0)\n",
    "    return movieGenresMatrix\n",
    "for i in range(n_items):\n",
    "#     iid = (np.where(X[:, 0] == i + 1)[0]).astype(int)\n",
    "\n",
    "#     if (len(iid) > 0) or :\n",
    "    X_train_count[i] = setGenresMatrix(X[i+1, 3])\n",
    "X_train_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=True, norm ='l2')\n",
    "tfidf = transformer.fit_transform(X_train_count.tolist()).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_items_rated_by_user(rate, user_id):\n",
    "    y = rate[:,0]\n",
    "    ids = np.where(y == user_id + 1)[0]\n",
    "    item_ids = rate[ids, 1] - 1\n",
    "    scores = rate[ids, 2]\n",
    "    return (item_ids, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(Yhat, rates, W, b):\n",
    "    se = 0\n",
    "    cnt = 0\n",
    "    for n in range(n_users):\n",
    "        ids, scores_truth = get_items_rated_by_user(rates, n)\n",
    "        scores_pred = Yhat[ids, n]\n",
    "        e = scores_truth - scores_pred \n",
    "        se += (e*e).sum(axis = 0)\n",
    "        cnt += e.size \n",
    "    return np.sqrt(se/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = tfidf.shape[1] # data dimension\n",
    "W = np.zeros((d, n_users))\n",
    "b = np.zeros((1, n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0371836405845278\n"
     ]
    }
   ],
   "source": [
    "for n in range(n_users):    \n",
    "    ids, scores = get_items_rated_by_user(rate_train, n)\n",
    "    clf = Ridge(alpha= 98, fit_intercept  = True)\n",
    "    Xhat = tfidf[ids, :]\n",
    "\n",
    "    clf.fit(Xhat, scores)\n",
    "    W[:, n] = clf.coef_\n",
    "    b[0, n] = clf.intercept_\n",
    "Yhat = tfidf.dot(W) + b\n",
    "print(str(evaluate(Yhat, rate_test, W, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(Yhat, rate_train, user_id, limit):\n",
    "    a = np.zeros((n_items,))\n",
    "    recommended_items = []\n",
    "    items_rated_by_user, score = get_items_rated_by_user(rate_train, user_id)\n",
    "    for i in range(n_items):\n",
    "        if i not in items_rated_by_user:\n",
    "            a[i] = Yhat[i, user_id]\n",
    "    if len(a) < limit:\n",
    "        recommended_items = np.argsort(a)[-len(a):]\n",
    "    else:\n",
    "        recommended_items = np.argsort(a)[-limit:]\n",
    "    return recommended_items\n",
    "\n",
    "def evaluatePR(Yhat, Data_test, limit, data_size):\n",
    "    sum_p = 0\n",
    "    Pu = np.zeros((n_users,))\n",
    "    for u in range(n_users):\n",
    "        recommended_items = recommend(Yhat, rate_train, u, limit)\n",
    "        ids = np.where(Data_test[:, 0] == u)[0]\n",
    "        rated_items = Data_test[ids, 1]\n",
    "        for i in recommended_items:\n",
    "            if i in rated_items:\n",
    "                Pu[u] += 1\n",
    "        sum_p += Pu[u]\n",
    "    p = sum_p/(n_users * limit)\n",
    "    r = sum_p/(Data_test.shape[0] + 1)\n",
    "    print('%s::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), limit, p, r))\n",
    "# for i in range(120, 501, 10):\n",
    "#     evaluatePR(Yhat, rate_test, i, '1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
